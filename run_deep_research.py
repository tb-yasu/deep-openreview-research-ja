"""è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - å…¬é–‹ç‰ˆå®Ÿè¡Œãƒ—ãƒ­ã‚°ãƒ©ãƒ .

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æŒ‡å®šã•ã‚ŒãŸå­¦ä¼šã®è«–æ–‡ã‚’æ¤œç´¢ãƒ»è©•ä¾¡ã—ã€
ç ”ç©¶èˆˆå‘³ã«é–¢é€£ã™ã‚‹è«–æ–‡ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘ã—ã¦å ±å‘Šã—ã¾ã™ã€‚
"""

import argparse
import sys
from pathlib import Path
from typing import Optional

from dotenv import load_dotenv
from loguru import logger

# Load environment variables from .env file
load_dotenv()

from app.paper_review_workflow.agent import create_graph, invoke_graph
from app.paper_review_workflow.models.state import (
    PaperReviewAgentInputState,
    EvaluationCriteria,
)
from app.paper_review_workflow.config import LLMConfig, LLMModel


def setup_logger(verbose: bool = False) -> None:
    """ãƒ­ã‚¬ãƒ¼ã‚’è¨­å®š."""
    logger.remove()
    log_format = (
        "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
        "<level>{level: <8}</level> | "
        "<level>{message}</level>"
    )
    logger.add(
        sys.stderr,
        format=log_format,
        level="DEBUG" if verbose else "INFO",
    )


def parse_arguments() -> argparse.Namespace:
    """ã‚³ãƒžãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æž."""
    parser = argparse.ArgumentParser(
        description="è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ç ”ç©¶èˆˆå‘³ã«åŸºã¥ã„ã¦è«–æ–‡ã‚’æ¤œç´¢ãƒ»è©•ä¾¡ã—ã¾ã™",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # è‡ªç„¶è¨€èªžã§ç ”ç©¶èˆˆå‘³ã‚’æŒ‡å®š
  python run_paper_review.py --venue NeurIPS --year 2025 \\
    --research-description "ã‚°ãƒ©ãƒ•ç”Ÿæˆã¨å‰µè–¬ã¸ã®å¿œç”¨ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™"

  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã§æŒ‡å®š
  python run_paper_review.py --venue NeurIPS --year 2025 \\
    --research-interests "graph generation,drug discovery,molecular design"

  # è©³ç´°è¨­å®š
  python run_paper_review.py --venue NeurIPS --year 2025 \\
    --research-description "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨LLMã¸ã®å¿œç”¨" \\
    --top-k 50 --min-relevance-score 0.3 --model gpt-4o
        """,
    )
    
    # å¿…é ˆå¼•æ•°
    parser.add_argument(
        "--venue",
        type=str,
        required=True,
        help="å­¦ä¼šåï¼ˆä¾‹: NeurIPS, ICML, ICLRï¼‰",
    )
    parser.add_argument(
        "--year",
        type=int,
        required=True,
        help="é–‹å‚¬å¹´ï¼ˆä¾‹: 2025ï¼‰",
    )
    
    # ç ”ç©¶èˆˆå‘³ã®æŒ‡å®šæ–¹æ³•ï¼ˆã©ã¡ã‚‰ã‹ä¸€æ–¹ã‚’æŒ‡å®šï¼‰
    research_group = parser.add_mutually_exclusive_group(required=True)
    research_group.add_argument(
        "--research-description",
        type=str,
        help="ç ”ç©¶èˆˆå‘³ã‚’è‡ªç„¶è¨€èªžã§è¨˜è¿°ï¼ˆæŽ¨å¥¨ï¼‰",
    )
    research_group.add_argument(
        "--research-interests",
        type=str,
        help="ç ”ç©¶èˆˆå‘³ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ãƒ³ãƒžåŒºåˆ‡ã‚Šã§æŒ‡å®šï¼ˆä¾‹: 'LLM,efficiency,fine-tuning'ï¼‰",
    )
    
    # è©•ä¾¡åŸºæº–
    parser.add_argument(
        "--min-relevance-score",
        type=float,
        default=0.2,
        help="æœ€å°é–¢é€£æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.2ï¼‰",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=100,
        help="LLMè©•ä¾¡å¯¾è±¡ã¨ã™ã‚‹è«–æ–‡ã®ä¸Šä½ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ï¼‰",
    )
    parser.add_argument(
        "--max-papers",
        type=int,
        default=9999,
        help="æ¤œç´¢ã™ã‚‹æœ€å¤§è«–æ–‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 9999ï¼‰",
    )
    parser.add_argument(
        "--focus-on-novelty",
        action="store_true",
        default=True,
        help="æ–°è¦æ€§ã‚’é‡è¦–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰",
    )
    parser.add_argument(
        "--focus-on-impact",
        action="store_true",
        default=True,
        help="ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’é‡è¦–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰",
    )
    
    # LLMè¨­å®š
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-4o-mini",
        choices=["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"],
        help="ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4o-miniï¼‰",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=0.0,
        help="LLMæ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ0.0-1.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.0ï¼‰",
    )
    parser.add_argument(
        "--max-tokens",
        type=int,
        default=1000,
        help="LLMæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ï¼‰",
    )
    
    # å‡ºåŠ›è¨­å®š
    parser.add_argument(
        "--output-dir",
        type=str,
        default="storage/outputs",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: storage/outputsï¼‰",
    )
    parser.add_argument(
        "--output-file",
        type=str,
        default=None,
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: paper_review_report_{venue}_{year}.mdï¼‰",
    )
    parser.add_argument(
        "--top-n-display",
        type=int,
        default=10,
        help="ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è¡¨ç¤ºã™ã‚‹è«–æ–‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰",
    )
    
    # ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º",
    )
    parser.add_argument(
        "--no-llm-eval",
        action="store_true",
        help="LLMè©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰",
    )
    
    return parser.parse_args()


def get_llm_model(model_name: str) -> LLMModel:
    """ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰LLMModelã‚’å–å¾—."""
    model_map = {
        "gpt-4o": LLMModel.GPT4O,
        "gpt-4o-mini": LLMModel.GPT4O_MINI,
        "gpt-4-turbo": LLMModel.GPT4_TURBO,
    }
    return model_map.get(model_name, LLMModel.GPT4O_MINI)


def run_paper_review(args: argparse.Namespace) -> None:
    """è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ."""
    logger.info("=" * 100)
    logger.info("ðŸ“š è«–æ–‡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    logger.info("=" * 100)
    
    try:
        # LLMè¨­å®š
        llm_config = LLMConfig(
            model=get_llm_model(args.model),
            temperature=args.temperature,
            max_tokens=args.max_tokens,
        )
        
        # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        logger.info("ðŸ”§ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åˆæœŸåŒ–ä¸­...")
        graph = create_graph(llm_config=llm_config)
        
        # ç ”ç©¶èˆˆå‘³ã‚’å–å¾—
        if args.research_description:
            research_description = args.research_description
            research_interests = []  # è‡ªå‹•æŠ½å‡ºã•ã‚Œã‚‹
        else:
            research_description = None
            research_interests = [k.strip() for k in args.research_interests.split(",")]
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        input_data = PaperReviewAgentInputState(
            venue=args.venue,
            year=args.year,
            keywords=None,  # åŒç¾©èªžãƒžãƒƒãƒãƒ³ã‚°ã‚’æ´»ç”¨
            max_papers=args.max_papers,
            evaluation_criteria=EvaluationCriteria(
                research_description=research_description,
                research_interests=research_interests,
                min_relevance_score=args.min_relevance_score,
                min_rating=None,  # æŽ¡æŠžè«–æ–‡ã¯å“è³ªãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹
                enable_preliminary_llm_filter=False,
                top_k_papers=args.top_k if not args.no_llm_eval else None,
                focus_on_novelty=args.focus_on_novelty,
                focus_on_impact=args.focus_on_impact,
            ),
        )
        
        # å®Ÿè¡Œæ¡ä»¶ã‚’è¡¨ç¤º
        logger.info(f"\nðŸ“‹ å®Ÿè¡Œæ¡ä»¶:")
        logger.info(f"   å­¦ä¼š: {args.venue} {args.year}")
        if research_description:
            logger.info(f"   ç ”ç©¶èˆˆå‘³: {research_description}")
        else:
            logger.info(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(research_interests)}")
        logger.info(f"   LLMãƒ¢ãƒ‡ãƒ«: {args.model}")
        logger.info(f"   æœ€å°é–¢é€£æ€§ã‚¹ã‚³ã‚¢: {args.min_relevance_score}")
        logger.info(f"   æœ€å¤§è«–æ–‡æ•°: {args.max_papers}")
        if not args.no_llm_eval:
            logger.info(f"   LLMè©•ä¾¡å¯¾è±¡: ä¸Šä½{args.top_k}ä»¶")
        else:
            logger.info(f"   LLMè©•ä¾¡: ã‚¹ã‚­ãƒƒãƒ—")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
        logger.info("\nðŸš€ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œä¸­...")
        result = invoke_graph(
            graph=graph,
            input_data=input_data.model_dump(),
            config={
                "recursion_limit": 100,
                "thread_id": f"{args.venue}_{args.year}",
            },
        )
        
        # çµæžœã‚’å–å¾—
        papers = result.get("papers", [])
        evaluated_papers = result.get("evaluated_papers", [])
        ranked_papers = result.get("ranked_papers", [])
        llm_evaluated_papers = result.get("llm_evaluated_papers", [])
        re_ranked_papers = result.get("re_ranked_papers", [])
        top_papers = result.get("top_papers", [])
        paper_report = result.get("paper_report", "")
        synonyms = result.get("synonyms", {})
        
        # ã‚µãƒžãƒªãƒ¼è¡¨ç¤º
        logger.info("\n" + "=" * 100)
        logger.info("ðŸ“Š å®Ÿè¡Œçµæžœã‚µãƒžãƒªãƒ¼")
        logger.info("=" * 100)
        logger.success(f"âœ“ æ¤œç´¢: {len(papers)}ä»¶ã®è«–æ–‡ã‚’ç™ºè¦‹")
        logger.success(f"âœ“ è©•ä¾¡: {len(evaluated_papers)}ä»¶ã®è«–æ–‡ã‚’è©•ä¾¡")
        logger.success(f"âœ“ ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(ranked_papers)}ä»¶ã®è«–æ–‡ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘")
        if not args.no_llm_eval:
            logger.success(f"âœ“ LLMè©•ä¾¡: {len(llm_evaluated_papers)}ä»¶ã®è«–æ–‡ã‚’è©•ä¾¡")
            logger.success(f"âœ“ å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(re_ranked_papers)}ä»¶ã®è«–æ–‡ã‚’å†ãƒ©ãƒ³ã‚¯ä»˜ã‘")
        logger.success(f"âœ“ é¸å‡º: {len(top_papers)}ä»¶ã®è«–æ–‡ã‚’é¸å‡º")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨åŒç¾©èªžã‚’è¡¨ç¤º
        if synonyms:
            logger.info("\n" + "=" * 100)
            logger.info("ðŸ”‘ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨åŒç¾©èªž")
            logger.info("=" * 100)
            for keyword, syns in synonyms.items():
                syns_display = ", ".join(syns[:5])
                if len(syns) > 5:
                    syns_display += f" ä»–{len(syns) - 5}å€‹"
                logger.info(f"ðŸ“Œ {keyword}")
                logger.info(f"   â”” åŒç¾©èªž: {syns_display}")
        
        # ãƒˆãƒƒãƒ—Nè«–æ–‡ã‚’è¡¨ç¤º
        if top_papers and args.top_n_display > 0:
            logger.info("\n" + "=" * 100)
            logger.info(f"ðŸ† ãƒˆãƒƒãƒ—{args.top_n_display}è«–æ–‡")
            logger.info("=" * 100)
            
            for paper in top_papers[:args.top_n_display]:
                logger.info(f"\n{'=' * 80}")
                logger.info(f"ã€ç¬¬{paper['rank']}ä½ã€‘ {paper['title']}")
                logger.info("")
                
                # è‘—è€…
                authors_list = paper['authors']
                authors_display = ', '.join(authors_list[:5])
                if len(authors_list) > 5:
                    authors_display += f" ä»–{len(authors_list) - 5}å"
                logger.info(f"**è‘—è€…**: {authors_display}")
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                if paper.get('keywords'):
                    keywords_list = paper['keywords']
                    keywords_display = ', '.join(keywords_list[:8])
                    if len(keywords_list) > 8:
                        keywords_display += f" ä»–{len(keywords_list) - 8}å€‹"
                    logger.info(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {keywords_display}")
                logger.info("")
                
                # æ¦‚è¦
                if paper.get('abstract'):
                    logger.info("#### æ¦‚è¦")
                    logger.info("")
                    abstract = paper['abstract']
                    if len(abstract) > 400:
                        abstract = abstract[:400] + "..."
                    logger.info(abstract)
                    logger.info("")
                
                # ã‚¹ã‚³ã‚¢
                logger.info("#### ã‚¹ã‚³ã‚¢")
                logger.info("")
                if paper.get('final_score') is not None:
                    logger.info(f"| **æœ€çµ‚ã‚¹ã‚³ã‚¢**         | **{paper['final_score']:.3f}** |")
                if paper.get('overall_score') is not None:
                    logger.info(f"| OpenReviewç·åˆ         | {paper['overall_score']:.3f} |")
                if paper.get('relevance_score') is not None:
                    logger.info(f"| ã€€â”œ é–¢é€£æ€§             | {paper['relevance_score']:.3f} |")
                if paper.get('novelty_score') is not None:
                    logger.info(f"| ã€€â”œ æ–°è¦æ€§             | {paper['novelty_score']:.3f} |")
                if paper.get('impact_score') is not None:
                    logger.info(f"| ã€€â”” ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ         | {paper['impact_score']:.3f} |")
                if paper.get('llm_relevance_score') is not None:
                    logger.info(f"| AIè©•ä¾¡ï¼ˆé–¢é€£æ€§ï¼‰       | {paper['llm_relevance_score']:.3f} |")
                if paper.get('llm_novelty_score') is not None:
                    logger.info(f"| AIè©•ä¾¡ï¼ˆæ–°è¦æ€§ï¼‰       | {paper['llm_novelty_score']:.3f} |")
                if paper.get('llm_practical_score') is not None:
                    logger.info(f"| AIè©•ä¾¡ï¼ˆå®Ÿç”¨æ€§ï¼‰       | {paper['llm_practical_score']:.3f} |")
                if paper.get('rating_avg') is not None:
                    logger.info(f"| OpenReviewè©•ä¾¡         | {paper['rating_avg']:.2f}/10 |")
                logger.info("")
                
                # OpenReviewè©•ä¾¡
                if not args.no_llm_eval:
                    logger.info("#### OpenReviewè©•ä¾¡")
                    logger.info("")
                    rationale = paper.get('evaluation_rationale', '')
                    if rationale:
                        logger.info(rationale[:300] + ("..." if len(rationale) > 300 else ""))
                    else:
                        review_count = len(paper.get('reviews', []))
                        rating_info = f"å¹³å‡{paper['rating_avg']:.2f}/10" if paper.get('rating_avg') else "è©•ä¾¡ãªã—"
                        decision = paper.get('decision', 'N/A')
                        logger.info(f"ã“ã®è«–æ–‡ã¯{review_count}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å—ã‘ã€{rating_info}ã®è©•ä¾¡ã‚’ç²å¾—ã—ã¾ã—ãŸã€‚")
                        logger.info(f"æŽ¡æŠžåˆ¤å®šã¯ã€Œ{decision}ã€ã§ã™ã€‚")
                        
                        # ç™ºè¡¨å½¢å¼ã‚’è¡¨ç¤ºï¼ˆNeurIPSãªã©ã®å ´åˆï¼‰
                        if decision and decision != 'N/A':
                            decision_lower = decision.lower()
                            if "oral" in decision_lower:
                                logger.info("  â”” ðŸŽ¤ ç™ºè¡¨å½¢å¼: Oral Presentationï¼ˆå£é ­ç™ºè¡¨ï¼‰")
                            elif "spotlight" in decision_lower:
                                logger.info("  â”” âœ¨ ç™ºè¡¨å½¢å¼: Spotlight Presentation")
                            elif "poster" in decision_lower:
                                logger.info("  â”” ðŸ“Š ç™ºè¡¨å½¢å¼: Poster Presentation")
                    logger.info("")
                    
                    # Meta Reviewï¼ˆã‚¨ãƒªã‚¢ãƒã‚§ã‚¢ã®ã¾ã¨ã‚ï¼‰
                    if paper.get('meta_review') and paper['meta_review'].strip():
                        logger.info("#### ðŸ“‹ Meta Reviewï¼ˆã‚¨ãƒªã‚¢ãƒã‚§ã‚¢ã®ã¾ã¨ã‚ï¼‰")
                        logger.info("")
                        meta_review = paper['meta_review']
                        if len(meta_review) > 200:
                            meta_review = meta_review[:200] + "..."
                        logger.info(meta_review)
                        logger.info("")
                    
                    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è¦ç´„ï¼ˆæœ€åˆã®1ä»¶ã®ã¿è¡¨ç¤ºï¼‰
                    reviews = paper.get('reviews', [])
                    if reviews and len(reviews) > 0:
                        first_review = reviews[0]
                        if first_review.get('summary') or first_review.get('strengths'):
                            logger.info("#### ðŸ“Š ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
                            logger.info("")
                            if first_review.get('strengths'):
                                strengths = first_review['strengths']
                                logger.info("**å¼·ã¿:**")
                                logger.info(strengths[:150] + ("..." if len(strengths) > 150 else ""))
                    logger.info("")
                    
                    # AIè©•ä¾¡
                    if paper.get('llm_rationale'):
                        logger.info("#### AIè©•ä¾¡ï¼ˆå†…å®¹åˆ†æžï¼‰")
                        logger.info("")
                        llm_rationale = paper['llm_rationale']
                        if len(llm_rationale) > 250:
                            llm_rationale = llm_rationale[:250] + "..."
                        logger.info(llm_rationale)
                        logger.info("")
                
                # ãƒªãƒ³ã‚¯
                logger.info("**ðŸ”— ãƒªãƒ³ã‚¯**:")
                logger.info(f"- OpenReview: {paper['forum_url']}")
                if paper.get('pdf_url'):
                    logger.info(f"- PDF: {paper['pdf_url']}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        if paper_report:
            output_dir = Path(args.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            if args.output_file:
                output_file = output_dir / args.output_file
            else:
                output_file = output_dir / f"paper_review_report_{args.venue}_{args.year}.md"
            
            output_file.write_text(paper_report, encoding="utf-8")
            
            logger.info("\n" + "=" * 100)
            logger.success(f"ðŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
            logger.info(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(paper_report) / 1024:.1f} KB")
            logger.info(f"   è¡Œæ•°: {len(paper_report.splitlines())}è¡Œ")
            logger.info("=" * 100)
        
        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°è¡¨ç¤º
        errors = result.get("error_messages", [])
        if errors:
            logger.warning(f"\nâš ï¸  {len(errors)}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:")
            for i, error in enumerate(errors[:3], 1):
                logger.warning(f"  {i}. {error}")
            if len(errors) > 3:
                logger.warning(f"  ...ä»–{len(errors) - 3}ä»¶")
        
        logger.info("\nâœ¨ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if args.verbose:
            import traceback
            logger.error(traceback.format_exc())
        sys.exit(1)


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°."""
    args = parse_arguments()
    setup_logger(verbose=args.verbose)
    run_paper_review(args)


if __name__ == "__main__":
    main()

