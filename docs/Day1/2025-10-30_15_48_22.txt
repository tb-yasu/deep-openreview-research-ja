

はい、ありがとうございます。はい、えっとここから20分くらいちょっと最後の。エアエージェントの品質、担保っていうテーマでお話しできればなと思います。で、えっと。その最初の方は、説明パートになるんですけど、


えっと、なんでちょっと、えっと、先ほど高木さんからの説明があったので、若干重複するんですけど、なんで評価テストをする必要があるか。っていうと、まあと評価テスト。開発初期のバグを防ぐというだけじゃなくて、


イギリスでも、あの社会的なリスクだったり、性能の劣化がないかっていうのを、基本的にチェック。ところで、必要になってくると、え、テストに関して言うと、き、えっと、当たり前、品質の保証みたいなところで、あのシステムが使用通りに正しく動くかっていうのをチェックしたり、


あとはシステムアップデートした際に、以前の機能がこれ壊れていないからしてないんだっていうのを、あの防ぐために、あの必要になって。評価で言うと、女性の構造とか、改善のらしい番組みたいなところで必要な。えっと、


AIのまあ、AIで言うと、AIの能力を測って、あの改善点を見つけるみたいなところで、あの評価していないと。というところだったり、あとは、特定のベンチマークで、あのひょう、あの評価セットを使って、あのモデル、


a,モデルbで比較して、あの自社のモデルaがどれだけ優れていくかみたいなところを確認したり、するとあとはどんな状況で、あのう、どういった助けであの、得意えっと性能がよく良くて、あの、そういったタスクで、


あの性能が悪い。悪くなる、苦手に、なんかみたいなところを、あの正しくシステムの特性を理解するっていうところでも評価が必要な。ところで、やっと評価大事ですよねっていうお話です。ええっと、どの順番で着手すればいいの？


みたいなところで言うと、あくまでえっと、我々のえっとアルマティックなケースではあるんですけど、こんな感じで、えっと、4段階であの進めていくっていうところを意識しています。えっと、定量評価っていうと、えっとテストセットを作成しないといけないところで、


結構、その評価指標をえっと。アドえっとドリフトとか、コンセント、ドリフトみたいなところが発生しやすいので、あの、実際にその評価セットを作る。行くところを想定していただければ分かるかなと思うんですけど、


このアノテーションする上で、その1軒目にテーションしたものと、1件目にあのテーションしたもので、結構、あの採点の基準がバラバラになってしまうみたいなことは、よくあるかなと思っていて、なんでその手取りが結構しやすいというのが、


定量評価。なぜ、手取りが多い？経営評価は、なるべく、こう後回しにして、あのリンに評価できるようにっていうのが、あの我、我が多分意識している部分であります。えっと、これで言うと、障壁の解体をまずやります。


で、異常形成状況テストをやります。で点数評価を選ぶときあって、えっと営業をやると、障壁の解体何かというと、えっとチームの間で、あと、AIの特性みたいなところを共有しましょう。というのが、正直の解体ですね。


特にこう初期段階においては、チームで、その情報の非対称性みたいなところが、発生しやすいので。チームメンバーで、あの、だいたいこのAIはどれくらいできるんだっていうか、そういったところ、よりリスクが発生しやすいんだっけ、


みたいなところを、あの認識のすり合わせをするっていうのが正。性能形状況テストみたいなところで言うと、あの初期段階は、特にそのシナリオが曖昧だったり、あの使用使用みたいなことが曖昧になったりするので、まずは使用を整理しましょうっていう意味でも、


あの正常形状形テストをやりますと、えっとここまでできたら、こう、今度訂正評価とか、エラー分析やって、最後、えっと、運用段階。プラクション、最後でプレイする前とかね。というふうか。あの実際にテストセットを収集して、


やるみたいな感じで進めていくということが、割と多いのかなと思います。で、えっと評価ってめちゃくちゃ難しい。実際に開発されている方は、ですけど、特にその生成対策の評価ってめちゃくちゃ難しい。あのー、例えば、


抽出タスクとか、そのタスク、1分類みたいなところで言うと、今はある程度、人が見て判断できる場合が多いんですけど、えっと、生成タスク、例えばレポートに対して、そのレポートがいい悪いんだっけ？みたいなところは、


結構正解の判定基準が曖昧である。あとは放送の受け入れ基準が存在。えっと、例えば記事。その本のメディアで、こう企業を発信しているような会社であれば、おそらく、そのレポートの受け入れ基準っていうのが存在するかなと思うんですけど、


多くの会社はそうじゃないかなと思っていて、そういった場合に、こう評価基準が曖昧であると。とかあとは実際に受け入れ、もう、実績のデータ、実際にその生成されたレポートに対して、いい悪いっていうその実績のデータが、


実際にえっ？と蓄積されていれば、それが評価データとして使用できるんだけど、多くの場合、イコールドスタートとなる場合が多いので、中でも生成タスクの評価は難しいです。じゃあ、どうすればいいかというところですけど、


あの赤木さんから説明あったように、1つの解として、あのエムアザージャッジととえっと監視を採用するみたいなところは1つあるかなと思います。えっと、どういうことかというと。まあ、えっと高品質な、まあ、ガードレールって書いてあるんですけど、


リームアザジャッジが高品質やるっていうのが、あの前提ではあるんですけど、あのリカレントフリーな評価と交換可能かなと。ええっと、例えば良い喉頭かみたいなところを判断することを考えた時、1つのえっと評価の観点として、


えっと、応答形式を順守しているか？みたいな観点が考えられるかなと。ええっと、これに関して言う。えっと、応答応答形式を順守しているかどうかっていうのを、あの高精度に判定可能なこと、ガードレールフレーム、


アザージャという、をあの設置して、それを監視しておけば、えっと、例えば通過率を見て、えっと百件中98件通過しました。が分かったとすると、大体出力は音消しをしているよね、っていうのが分かるので、あのゲームアザージャッジとしての組み合わせて、


あのシステムが生きていけてないかみたいなところを判断するというのが、あのあったりします。というところです。はい。で、えっと、ここからあの実際に評価。まあ、評価っていうか、えっと、さっきのパブリットコンテンツを体していきましょうっていう話に、


あのつなげていければなと。で、えっと、ちょっとこ。コーヒーブレイクみたいな感じで、あの良くない評価の例を、ちょっと載せてみました。えっと、ここで、はっと、オープンエアの作者ダウトクを使ってと、ユーザーフルエンスコアっていうのを取るが、


ユーザーにとって有益です。判断しようとしています。ええっと、例えば、アシスタントの糖分を、有益さの観点から、1から10点で評価しているというような、まあ、エンドラッジを作ったとします。で、これってめちゃくちゃいけてないんですよね。


なんでいけてないかというと、まあ10回例えば回しますと、あります。みて。その結果を確認してみると、まあまあ、ちょっとイケてそうな、そんな結果が出てるんですけど、あの結構、ばらつきが出てしまうとは、えっと、


ばらつきが出てしまうと、こう事項ごとに評価の値が変わってしまうので、あの、そもそも、あの評価消化としての信頼が、あの担保できないというのがあるかなと思い、なんでえっとばらつきを？抑制してしましょうっていうのが、


あの評価で、大事ジャンルの再現性を担保するというところが、評価で大事になってくるかなと思います。ええっと、ばらつきが発生する原因。まあ、先ほどの例を見る。この応答の有益さ、1から10点で評価してみたいなのが、


なんで悪いかって言うと、有益さって言ってるんだけど、それって、その多様な解釈が発生しますよね？っていうところだったり、やっぱ1から10点って、あの評価して言ってるんだけど、あの10段階評価。ではあるんだけど、


それはどういった場合に何点をつければいいかとか、そういった粒度で、あの、知事は、指示をしてないので、あいに移動する形になっているんです。なんでそのエルに依存した？例えば、ルールが変わった場合に、評価があの大幅に変わってしまうみたいな。


ところが達成して、あの再現性が悪い、低いっていうような形で、なのかあるかなと。で、えっと、良いプロンプトの条件みたいなところ。ちょっと書いて。良いプロンプトの条件っていうのは、1つは、えっと、第三者がその指示に従った場合に、


その遂行の再現が可能であることだと思っています。具体的には、もう少し丁寧に言うと、予言の抜け漏れがなく、詳細な記述内容であること。顧客の要求を反映した推論手順が丁寧に記載され、が、あのわりと大事になってくるかなと。


えっとよ、めちゃくちゃ丁寧に書かれたあの論とっていうのは。例えば、エリーが生成誤りを起こしましたという時に、あのその原因って、フロントにあるのか、ルーにあるのかっていうのは、結構わかなかったりするんですよね。


で、プロンプトがめちゃくちゃ丁寧になると、えっと、プロットはまあ悪くないだろうというが、あの推論能力をかけてたんだろうというところで、エムに責任ある程度、その、支持の追従性が悪かったというところで、責任転嫁できるっていうので、


あの詳細なフロントは重要ですと、もう1つが顧客に説明できるっていうのが、結構大事なポイントかなと思います。えっと、どういうことかというと、えっと、顧客要求を反映した推論手順が丁寧に記載されたブログ取って、


一定の責任、説明責任を持つかなと。えっと、例えば採点タスクというと、えっと採点タスクにおいて納得感をどうあの醸成するかみたいなところを言うと、例えば、観点の網羅性をどういった観点で評価するかというと、


あと各観点において、どういった場合に一点どういったバインに3点といた根拠の論理性みたいなところが保証されていると、お客さんが納得感が増すかなといって、こういったものが新しくオンボーディングのボーリングされていれば、


まあ、丁寧な設計そのものが、あのお客さんにあの説明できますよねっていうところで、まあ、1つ良いロープとも、あの条件として、あの、お客さんの要求を反映した丁寧なプロンプトというのが。ここまでまか置きなんですが、


実際に、ちょっとサブミットコンテントっていうのは、先ほど、あのアクトエール。だいたい良さそうだよねってなったコンテントに対して、あの提出するこのツールとして呼び出すサウンドコンテンツというのがあったんですけど、


それをちょっと改善してみようかなと改善して、ちょっと今回は。えっと、ここの場合は終わろうかなと思うんですけど。えっと、タブレットコンテントはどういった内容であったかっていうと。ちょっとおさらいすると、


えっとサミッションというデータ型を返すような、あのツールでありました。ええっと、中身で言うと、ステータスとアクセプティブとか、インクルームとか、リジェクティブの3つのステータスのいずれかを返す。で、その受け入れ判断の詳細の理由も一緒に返すというようなものがアメリットで。


プロットはこんな形で書いています。ちょっと、さっさっき説明してなかったかなと思うんですけど。えっと、よくあるなしですね。あなたのマスクは、以下の評価基準の観点をもとに、こういう専門的に検出ルールを審査し、


分かりやすく理論を行うことですと、その評価基準というのは、あのこういった形で、あのジリーの場合は、より完全性を満たして、完全性、正確性、構造もいい構造で、こういった条件を満たした場合に、アクセントと判断すると、


インフルーブルも、こういった条件でインフルを。えーっと、えっと不完全な内容だったり、不安した記述であれば、エレクティックを返すみたいな感じで、サブミットコンテント書いてました。で、ただこれっていけてないかなと思うんですよね。


行けてない、行けてなさみたいなところで言うと、えっとこれ、えっと、例えば、この結果を監視しました。ことを考えた時に監視したからが監視したことによる嬉しさっていうのがあんまりないかなと思っていて、このステータスを返すっていうところだけだと、


AIエージェントの生成能力を知るすべがない。今で言うと、AIエンジンの生成物に対する観測が、あのちょっと間違ってますけど、えっと、ステータス、このアクセストされたかと改善のつあるか、リジェクトするかっていう、


あの、その観点でしかないと。本来は、この評価基準、安全性とか、正確性とか、そういった観点に照らし合わせて評価をしてあげるしてほしいと。例えば、コンテ、部分から検索されたページ情報に対する忠実で、クイズプレースみたいなところが、


ところを、その観測点として持ってあげて、そこが弱かったら、そのウェブ情報をちゃんとあの参照してないですよね、みたいなところで、AIエージェントに対する性の説明ができるんですけど、あの現時点だと、それができないと。


あとえっと受理の可能性。えっと、授業の可能性。えっと今、サブスチョンの内容でそのステータスを直接生成するんですけど。ここのその推移されるかされないかというところの最終的な判断は、AIエージェントに依存しているというところで、


あの、それまでのこれまでになった動物家庭みたいなところが、あのいて不明瞭であるかなと思います。なんで、あの現時点のサブミットコントコンテントは、あんまりその運用みたいなところを考えると、あんまり行けてないんじゃないかなと思いますと。


じゃあ、会社の法制に行きましょうというところ。で、えっと改善方針。まあ、いろんな観点があります。えっと、例えば、えっと、先ほど、あの、忘れちゃったんですけど、あの仕事ができるかと。能力が高かった感じがあったと思うんですけど、


仕事ができるか、まあ、システムの外に。ある話かなと思って、例えば、そのこのAIを使うことでどれくらい？その、作業が効率化されるんだ。このレポートを、実際にその後、続のタスクで使うことで、渋谷といくら上がるか。


ところがあったり、システムの内部でいうと、生成物に対する評価が、あの生成過程に対する評価みたいなことで、生成過程に対する評価でいうと、処理速度どれくらいだった？あの作業過程に、どれくらい上昇性があるのか、


とか、そういったところも評価できるし、あの生成物について言うと、えっと、レポートとレポートのない内部で、あの閉じた話なのかと、レポートとユーザーの要求を比較して、あの、例えばユーザーが質問を投げました。


で、質問に対してそのレポートの回答が、ユーザーのユーザーの質問に対して、回答しているか、みたいなところで、正確性を判断したり、あとは、その検査結果を、しているということで、忠実性を判断したり、感じで、


いろんな観点が考えられると、こういった観点をまず解決しましょう。とで撤去した上で、あの優先付けしましょう。と、これを、あの主要観点として採用すると、インパクトがありますよ。今回は、ちょっと有用性の例を出したので、


あの有用性を対応しますが、本来は、あのいろんな観点があるので、ここでは、有用性だけを取り上げているので、あの、ここの評価自体も、あんまり網羅性がなくていけじゃないんですけど、いったんその有用性だけをピックアップして評価してみましょうと。


ええっと、先ほどのあの納得とみたいな。ところで言うと、あの根拠の論理性みたいなところで、こういった場合に、1.5か3.535点、みたいなところをちゃんとちゃんと書く。まあ、ちょっと若干曖昧な記述ではあるんですけど、


例えば、解決策を漏れなく提起をし、期待を上回る。実用的な洞察や、革新的な提案を含むみたいなことで、これであれば、5点を付与すると、そんな感じで、僕と書いで、えっと、サ症どう改善したかみたいなところで言うと、


先ほどのあのメトリックの、ここのえっと、根拠の論理性を1つ書いたのと、あとはもう1つ、えっと、受理可能か、可能であるかどうかっていう最終判断を、あのユーザーにユーザー側で持つようにしましたっていうので、


頑張ります。えっと、ここの。具体的に言うと、ここの場合で言うと、えっとメトリックの都会。有用性のスコアに応じて、えっと、受理されるかされないかというところの、えっと判断基準を持つようにしました。例えば、


そのすべての評価に、えっと、評価観点において、トーブ4点以上であればあたりしますよとか、そういったところ。えっと、これによってそのエネルギー、依存する部分をなるべく減らす。あのエレンに依存してしまうと、


どうしてもあの鼻基準が不明瞭になってしまうので、あ、こんな感じでコントロール可能。で、まあ、実際に評価をえっとアップローを書いてますね。本当はさっきえっとアクセプト。リジェクトでえっとそれぞれ書いてたんですけど、


えっと、今度はここの！この内容を含めるようにして、まあ、中身をちょっと見ていただければと思うんですけど、そういった感じで、あの評価観点をかけて、はい。えっと、はい。で、えっと、これを実行すると、こんな感じで、


えっとスコア四。第4点です。で、結果アクセプトですみたいな感じで、あの、と比べるとこう。そのアクセスの手前のあの、なんなんでそうなったかの？あの説明が割と、あの。わかりやすくな、ちょっと、あの実際に手を動かしながらっていう感じではなかったんですけど。


あの、こういった感じで、あの、また、ジャッジの改善していけるといいんじゃないかな、っていうお話でした。はい、ちょっと長くなってしまったんですけど、最後、あの後藤さんから。日本開発における落とせ！
