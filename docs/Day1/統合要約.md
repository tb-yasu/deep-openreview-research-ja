# AIエージェントワークショップ 統合要約

[リポジトリ](https://github.com/smiyawaki0820/wandb-fc-2025-agent-workshop)
[Colab](https://colab.research.google.com/drive/1tm2rNT_2axA5vklcagMlrFiH1vFozEHY?usp=sharing)

## 1. ワークショップの全体構成

電通総研主催によるAIエージェント技術の体系的なワークショップで、以下の4つの主要テーマで構成されています：

1. **技術的基礎と実装** (Part1)
2. **評価方法と改善サイクル** (Part2)
3. **品質担保とプロンプト設計** (Part3)
4. **実務的な議論とQ&A** (Part4)

---

## 2. 核心となる技術要素

### 2.1 エージェントアーキテクチャ

**2種類のエージェント設計パターン:**

- **ワークフロー型（LangGraph）**
  - 制御性・再現性重視
  - ノード・エッジ・ステート管理による明示的なフロー設計
  - ビジネス業務への導入に適する
  - Checkpointer機能による状態保存・再開可能

- **自律型（React Agent）**
  - 探索性・柔軟性重視
  - Reasoning（思考）→ Acting（行動）→ Observation（観測）のサイクル
  - 研究・創造型タスクに適する

### 2.2 主要技術コンポーネント

| 技術要素 | 役割 |
|---------|------|
| LangGraph | ワークフローベースの状態管理と制御 |
| Checkpointer | 実行状態の保存・再開・Human-in-the-loop実現 |
| Deep Research Agent | ヒアリング→タスク分解→調査→レポート生成の多段階処理 |
| Perplexity API | 外部検索・調査ツール連携 |
| Weave (W&B) | トレーシング・評価・実験管理プラットフォーム |

---

## 3. 評価と品質担保の体系

### 3.1 評価の3段階アプローチ

**開発段階:**
- 評価基準の設定
- テストデータセットの構築
- 難易度別（Hard/Normal/Easy）の段階的評価

**運用段階:**
- ユーザーフィードバックの収集
- リアルタイムモニタリング
- ログ分析とトレーシング

**改善段階:**
- 失敗原因の分析
- 評価データセットの拡充
- 継続的な基準見直し

### 3.2 主要評価指標

| 指標 | 説明 |
|------|------|
| 完全性（Completeness） | タスク要件の網羅度 |
| 根拠性（Groundedness/Faithfulness） | 事実・コンテキストへの忠実度 |
| 安全性（Safety） | 倫理的・法的リスクの回避 |
| 有用性（Usefulness） | 実務的価値・革新性 |

### 3.3 LLM Judge（自動評価）

- 人手評価の模倣による自動スコアリング
- コスト削減と客観性の向上
- **重要**: スコア単独ではなく「スコア＋説明」のセット出力が必須
- 人間評価とのハイブリッド運用が現実的

---

## 4. 実務導入における重要原則

### 4.1 プロンプト設計の3要件

1. **再現性**: 第三者が同様の結果を得られる
2. **詳細性**: 評価観点を明示的に分解・ルール化
3. **説明責任**: 顧客・経営層に論理的説明が可能

### 4.2 品質評価プロセス（4段階モデル）

1. **障壁の解体**: チーム間でAI特性とリスクの認識共有
2. **正常系テスト**: 仕様・シナリオの明確化
3. **訂正評価**: 不具合原因の特定と改善
4. **本番運用テスト**: 実データでの継続評価

### 4.3 段階的構築アプローチ

- 初期は人間介入を前提としたシンプル構成
- ノード単位で自動化範囲を徐々に拡大
- Human-in-the-loopによる安全設計
- ステート設計は極力シンプルに保つ（永続データは外部DB参照）

---

## 5. 運用上の実務的知見（Q&Aセッションより）

### 5.1 データ更新・蓄積

- RAG基盤サービス（Julep、Google、Azure）の活用
- 自動更新バッチによる属人化回避
- 中小企業向け: kintone + ベクトルDB連携

### 5.2 リグレッション防止

- ベンチマーク・標準データセットの固定
- 成功例をトレースログから抽出して評価セット拡充
- 段階的なテストカバレッジ向上

### 5.3 モデル選定

- タスク特化型やオフライン環境ではローカルLLM活用
- ノード設定によるモデル自動切替可能
- API差分による互換性問題に注意

### 5.4 AI導入成功の条件（成功率5%の背景）

**成功企業の共通点:**
- 継続的改善体制（学習の仕組み）の内製化
- 現場主導のナレッジ構築と熱量
- 入力データの高品質化
- 経営層による定量的効果測定支援

**失敗パターン:**
- インパクトの小さいタスク選定
- 評価指標の未定義
- 属人的運用

---

## 6. 重要な設計思想

### 6.1 評価の二軸構造

- **能力評価（頭の良さ）**: モデル性能・推論品質
- **成果評価（仕事の成果）**: タスク遂行力・実用性

この二軸を分離して評価することが重要。

### 6.2 責任分担の透明化

- LLMは評価と情報提供を担当
- 最終判断権限は人間側に配置
- 評価観点ごとのスコアと説明文を明示

### 6.3 継続的改善サイクル

- 評価は単発イベントではなく継続プロセス
- 現場ユーザーの声を初期指標化
- 数ヶ月のトライ運用を通じた自然な基準形成

---

## 7. 今後の研究・実装方向

**技術的課題:**
- 自己進化型エージェント（Self-evolution）
- 長期自律行動（Long-horizon agent）の安定性
- メモリ・ツール・プランニングの統合最適化
- 評価指標の標準化と比較可能性確保

**運用的課題:**
- 自動評価と人手評価の最適なハイブリッド設計
- 顧客説明可能な評価レポート標準化
- コスト・監査対応・データ管理の最適化
- グラウンドトゥルース構築コストの削減

---

## 8. 主要な実装ツール・プラットフォーム

- **開発**: LangChain, LangGraph
- **評価**: Weave (W&B), LLM Judge (EvalLM)
- **検索**: Perplexity API
- **データ基盤**: ベクトルDB各種、RAG基盤サービス
- **参考フレームワーク**: RAGAS (RAG Assessment Suite)

---

## まとめ

この要約は、技術的実装から品質管理、実務導入までを包括した体系的な知見を示しています。特に「**段階的構築**」「**現場主導**」「**評価サイクル**」が成功の鍵として繰り返し強調されています。

AIエージェント開発において最も重要なのは、技術力以上に**現場知識と運用設計力**であり、継続的な評価・改善を通じて「使われ続ける」エージェントを構築することが本質的な成功要因となります。

