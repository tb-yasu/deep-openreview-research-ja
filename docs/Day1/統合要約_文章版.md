# AIエージェントワークショップ 統合要約（文章版）

- [リポジトリ](https://github.com/smiyawaki0820/wandb-fc-2025-agent-workshop)
- [Colab](https://colab.research.google.com/drive/1tm2rNT_2axA5vklcagMlrFiH1vFozEHY?usp=sharing)

## はじめに

本ワークショップは、Weights&Biasesが主催するAIエージェント技術の最新動向と実践的開発手法を紹介する包括的なプログラムである。AI開発者や実務者を対象に、エージェントの設計、評価、運用に関する体系的な知見を提供し、LangGraphやDeep Research Agentなどの実装をハンズオン形式で体験する構成となっている。講演は技術的基礎、評価方法、品質担保、実務的議論の4つのパートで構成され、理論から実践までを網羅的に扱っている。

## AIエージェントの基本構造と設計思想

AIエージェントとは、環境を観測し、計画し、行動する自律的知能システムであり、意思決定の反復により目標達成を図る技術である。本ワークショップでは、エージェントの構成要素として知覚、記憶、計画、行動という4つの基本機能が紹介され、それぞれがどのように統合されるかが詳細に解説された。

エージェント設計には大きく分けて2つのアプローチが存在する。第一は「ワークフロー型」であり、LangGraphを用いた制御性と再現性を重視した設計である。このアプローチでは、ノード、エッジ、ステート管理により明示的なフローを構築し、ビジネス業務への導入に適している。特にCheckpointer機能により実行状態の保存と再開が可能となり、Human-in-the-loop（人間による承認プロセス）を容易に実装できる点が実務適用において極めて重要である。

第二は「自律型（React Agent）」であり、探索性と柔軟性を重視した設計である。このエージェントはReasoning（思考）、Acting（行動）、Observation（観測）のサイクルを繰り返し、研究や創造型タスクに適している。講演では、ワークフロー型が「再現性重視の業務エージェント」に、React Agentが「探索・創造型の研究エージェント」に適するという使い分けの指針が示された。

## 技術基盤とツールチェーン

実装面では、LangChainとLangGraphが中核的な開発基盤として位置づけられている。LangGraphは状態遷移を明示的に管理でき、チェックポイント機能により承認プロセスの自動化が可能である。西氏（LangChain日本公式サポート）の解説によれば、ステート保存による再開性と承認プロセスの自動化が実務適用の鍵となる。

具体的な実装例として、Deep Research Agentが詳細に紹介された。このエージェントは、ヒアリング、タスク分解、調査、レポート生成という明確な4段階のプロセスで構成され、Perplexity APIなどの外部ツールと連携して多段階の調査・分析を行う。宮城氏によるハンズオンでは、このプロセス設計がエージェント構築の基礎となることが強調された。

評価とモニタリングの基盤としては、Weights & BiasesのWeaveが紹介された。Weaveは実験管理、評価、トレーシングのためのプラットフォームであり、AIアプリやエージェントの行動ログを可視化することで、試行錯誤のプロセスを明示的に管理できる。講演者の後藤氏は、「試行錯誤の可視化」がエージェントの価値を示す重要な要素であると述べている。

## 評価の体系と自動化

AIエージェントの評価は、単なる性能測定ではなく、開発、運用、改善という3つの段階を通じた継続的なプロセスとして捉えられるべきである。講演では「頭が良い」だけでは「仕事ができる」わけではないという比喩を用いて、人間とAIエージェントの評価における共通課題が提起された。AIエージェントには「能力」だけでなく「信頼性」「安全性」「実用性」が必要であり、これらを二軸で評価する枠組みが提示された。

開発段階では、評価基準の設定とテストデータセットの構築が中心となる。難易度別（Hard/Normal/Easy）の段階的評価により、改善効果を定量化することが推奨される。運用段階では、ユーザーフィードバックの収集とリアルタイムモニタリングが重要であり、ログ分析とトレーシングを通じて実運用の状況を把握する。改善段階では、失敗原因の分析と評価データセットの拡充を行い、継続的に基準を見直すサイクルを確立する。

評価指標としては、完全性（Completeness）、根拠性（Groundedness/Faithfulness）、安全性（Safety）、有用性（Usefulness）という4つの主要な軸が提示された。完全性はタスク要件の網羅度を測り、根拠性は回答が事実やコンテキストに基づいているかを評価する。安全性は倫理的・法的リスクの回避を、有用性は実務的価値と革新性を測定する。

評価の自動化については、LLM Judge（EvalLMなど）の活用が詳しく解説された。LLM Judgeは人手評価を模倣して自動スコアリングを行い、コスト削減と客観性の向上を実現する。ただし、スコア単独ではなく「スコア＋説明」のセット出力が必須であり、人間評価とのハイブリッド運用が現実的であると強調された。Q&Aセッションでは、専門家のフィードバックをAI評価と照合する実験が進行中であることが報告され、完全自動化は困難であるものの、トレンド分析や数値トラッキングによる補助的評価は十分可能であることが示された。

## 品質担保とプロンプト設計

品質担保においては、テストと評価を明確に区別することが重要である。テストは「正しく動作しているか」を確認する工程であるのに対し、評価は「AIがどのように良い・悪い結果を出しているか」を分析し、改善点を明確にする継続的プロセスである。定量評価におけるアノテーションのばらつきや採点基準のドリフトが大きな課題として認識されている。

品質評価プロセスは4段階モデルで構造化される。第一段階は「障壁の解体」であり、チーム間でAI特性とリスクの認識を共有する。第二段階は「正常系テスト」で、仕様とシナリオを明確化し曖昧性を排除する。第三段階は「訂正評価・エラー分析」で不具合原因を特定し、第四段階は「本番運用テスト」で実データを用いた継続的評価を行う。

プロンプト設計においては、3つの要件が提示された。第一は「再現性」であり、第三者が同様の結果を得られることが求められる。第二は「詳細性」で、評価観点を明示的に分解しルール化する必要がある。第三は「説明責任」であり、顧客や経営層に論理的説明が可能でなければならない。講演では、「有益さを1〜10点で評価」といった曖昧なスコアリングでは再現性が低下する不良例が示され、評価軸を明確にして各観点に定量ルールを付与する改善策が提案された。

具体的な改良事例として、SubmitContentツールの改善が紹介された。旧仕様ではアクセプト/リジェクトの二値判断のみであったが、改善後は各評価観点（安全性、正確性、忠実性、有用性）に基づきスコアリングと説明文を生成し、最終判断をLLMから人間側へ移行することで評価基準の透明性が向上した。このアプローチは、LLMには評価と情報提供を担当させ、最終判断権限は人間側に配置するという責任分担の明確化を体現している。

## 実務導入の成功要因と課題

実務導入においては、段階的構築アプローチが強く推奨される。初期段階では人間介入を前提としたシンプルな構成から始め、ノード単位で自動化範囲を徐々に拡大していく。Human-in-the-loopによる安全設計を組み込み、ステート設計は極力シンプルに保つことが重要である。永続データは外部データベースでID参照する構成とし、スキーマ変更時の破損リスクを回避する設計が推奨される。

データ更新と蓄積に関しては、RAG基盤サービス（Julep、Google、Azure等）の活用により運用負担を軽減できる。自動更新バッチの導入により属人化を回避し、中小企業向けにはkintoneとベクトルDB連携のような簡易運用も有効であることが示された。

リグレッション（機能退行）防止については、ベンチマークや標準データセットを固定し、最低限の品質基準を維持する。ただし初期段階から完璧な評価セットを作るのは難しく、現場利用のトレースログから成功例を抽出して評価セットを拡充する段階的アプローチが現実的である。

モデル選定については、タスク特化型やオフライン環境ではローカルLLMが有効である一方、性能はクラウドモデルに劣ることが多く、使い分けがポイントとなる。ノード設定時にモデル指定情報を持たせることで、ユーザーフィードバックなどをトリガーに動的なモデル切替も実装可能である。ただしAPI差分による出力形式の互換性問題には注意が必要である。

AI導入の成功条件については、MITの調査で報告された「成功率5%」という数字を踏まえた議論が行われた。成功企業の共通点として、継続的改善体制（学習の仕組み）の内製化、現場主導のナレッジ構築と熱量、入力データの高品質化、経営層による定量的効果測定支援が挙げられた。逆に失敗パターンとしては、インパクトの小さいタスク選定、評価指標の未定義、属人的運用が指摘された。成功の鍵は技術力以上に「現場知識と運用設計力」であり、「現場の熱量」と「専門知識の言語化力」が本質的に重要であることが強調された。

開発初期に評価基準が定まらない場合の対応としては、現場ユーザーの声（アンケート、操作ログ）を初期指標とし、ベテランと新米双方の満足度や業務削減率を観察指標として活用する。最重要なのは「代行できているか（タスク遂行力）」であり、段階的にモデル評価からタスク評価へとシフトする。定量評価を急がず、数ヶ月のトライ運用を通じて自然に基準を形成するのが効果的であるとされた。

## 今後の展望と研究課題

今後の技術的方向性としては、自己進化型エージェント（Self-evolution）が注目されている。これは経験と評価を蓄積し自己改善するアーキテクチャであり、2025年の研究トレンドとして位置づけられている。また、長期自律行動（Long-horizon agent）の安定性と安全性、メモリ・ツール・プランニングを統合したLLMアーキテクチャの最適化も重要な研究課題である。

評価面では、評価指標の標準化と比較可能性の確保、自動評価と人手評価の最適なハイブリッド設計、顧客説明可能な評価レポートの標準化が課題として残されている。運用面では、コスト最適化、監査対応、データ管理の最適化、グラウンドトゥルース構築コストの削減が継続的な検討事項である。

講演全体を通じて、AIエージェントの社会実装には、技術的完成度以上に「人間業務との統合」「専門家レベルの成果物生成」「試行錯誤の可視化」が価値を生むという認識が共有された。評価を通して「人間の知的行動の写像」を理解することが重要であり、評価設計そのものがAI理解の深化につながるという高木氏の指摘は示唆に富んでいる。

## むすびにかえて

本ワークショップは、AIエージェント技術の理論的基礎から実装、評価、品質管理、実務導入までを包括的に扱った貴重な学習機会であった。全体を通じて繰り返し強調されたのは「段階的構築」「現場主導」「評価サイクル」という3つのキーワードである。これらは単なる技術論ではなく、AIシステムを現場で「使われ続ける」ものにするための本質的な成功要因を示している。

AIエージェント技術は発展途上であり、確立したベストプラクティスはまだ存在しない。だからこそ、評価手法も進化させ続ける必要があり、継続的な改善サイクルを回すことで初めて実務に耐えうるシステムが構築される。技術力だけでなく、現場知識、運用設計力、そして組織的な学習の仕組みを統合的に構築することが、AI導入成功への道筋となる。

