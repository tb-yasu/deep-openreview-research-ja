# AIエージェント評価ワークショップ講演ノート

## 概要（Summary）
本講演は、AIエージェントの**評価方法と改善サイクル**を体系的に整理し、開発・運用現場で実践的に活用できる評価の考え方を提示するものである。特に、**自動評価（LLM Judge）**の導入や、**評価指標の設計・運用プロセス**に焦点が当てられた。対象は、AIエージェント開発者・プロダクトマネージャ・研究者である。

---

## 講演の構成（Structure）

- **導入**
  - 「頭が良い」だけでは「仕事ができる」わけではないという比喩から、人間とAIエージェントの評価の共通課題を提起。  
  - AIエージェントにも「能力」だけでなく「信頼性」「安全性」「実用性」が必要。
- **背景**
  - AIエージェントの開発・運用では、各フェーズで異なる評価が必要。
  - 従来は人手評価が中心だったが、コスト・一貫性・客観性に課題。
- **技術的内容**
  - 開発・運用・改善の各段階での評価設計：
    - **開発段階**：基準設定・評価データセット構築。
    - **運用段階**：ユーザーフィードバックとモニタリング。
    - **改善段階**：失敗原因分析と再学習。
  - **評価自動化**の必要性とLLM Judge（例：EvalLM）の活用。
  - 代表的な**評価指標**：完全性、根拠性、安全性、類似性など。
  - RAG系モデル向けの評価指標：コンテキスト実証・忠実性（Faithfulness）。
- **事例／実践**
  - 自動評価による効率化と改善サイクルの高速化。
  - 難易度別テストセット（Hard/Normal/Easy）で段階的評価。
- **議論・質疑応答**
  - グラウンドトゥルースの定義の難しさ。
  - 定量指標と人間の判断のバランス。
- **まとめ**
  - 頭の良さと実務能力という二軸での評価。
  - 継続的な評価基準・データセットの見直し。
  - 評価と改善を繰り返すことで、現場で「使われ続ける」エージェントへ。

---

## 発言者別メモ（Speakers）

- **登壇者A（主講演者）**
  - **発言要旨**：
    - 評価は単発でなく、開発〜運用〜改善を通じたサイクルで継続的に行うべき。
    - 評価の自動化にはLLM Judgeを用いることで、人的コスト削減と客観性の向上が可能。
  - **重要なキーワード**：
    - 評価指標（完全性・根拠性・安全性）
    - LLM Judge（エレーナジャッジ）
    - モニタリング／改善サイクル
  - **特徴的な見解**：
    - 「AIエージェントには確立したベストプラクティスがまだない」ため、評価手法も進化させる必要がある。

---

## 技術・概念の整理（Key Concepts）

- **完全性（Completeness）**
  - 質問の全側面をカバーできているかを測る網羅性指標。
  - RAGなどで有効。
- **根拠性（Groundedness / Faithfulness）**
  - 回答が事実や与えられたコンテキストに基づいているか。
  - LLM評価の中心的尺度。
- **安全性（Safety）**
  - 出力内容がリスクを伴わず、倫理的・法的に安全であるか。
- **LLM Judge**
  - LLMによる自動評価モデル。人間評価を模倣しスコアリング可能。
- **グラウンドトゥルース（Ground Truth）**
  - 正解データセット。評価の信頼性確保に必須。
- **評価自動化**
  - 評価基準をプログラム化し、定常的に品質をチェックする手法。

---

## 実務・応用のポイント（Practical Insights）

- **ポイント1：**
  - 開発・運用・改善フェーズごとに評価軸を分け、サイクルを継続的に回す。
- **ポイント2：**
  - LLM Judgeなどの自動評価を導入し、人的負担を軽減しながら評価精度を維持。
- **ポイント3：**
  - グラウンドトゥルースを明確化し、評価の意味づけと改善根拠を明示。
- **ポイント4：**
  - 難易度別テストセットを用いて段階的評価を行うことで、改善効果を定量化。

---

## 今後の課題・議論点（Open Questions）

- 自動評価と人手評価の最適なハイブリッド運用。
- 評価指標の標準化と比較可能性の確保。
- 現場ごとに異なるKPI（ユーザー体験・安全性など）の統合方法。
- 評価データセット構築のコスト削減と更新プロセス。

---

## 自分の気づき／補足（Personal Notes）

- 「頭の良さ」と「仕事の成果」を分けて評価する観点は、研究プロジェクト評価にも応用できる。
- RAG評価指標（Faithfulness, Context Recallなど）は、自身のRAS/Graph-RAG研究のメトリクス設計にも関連。
- 今後、**LLM Judge × JSONL構造化出力**の組み合わせによる自動評価パイプラインを設計する価値がありそう。
- 次に読むべき参考資料：
  - OpenAI “Model Spec”の評価関連節
  - Anthropic “LLM-as-a-Judge”論文
  - RAGAS（RAG Assessment Suite）の評価指標仕様
