
# AIエージェント品質・評価ワークショップ講演ノート

## 概要（Summary）
本講演では、AIエージェントの**品質担保と評価設計**を中心に、開発現場での具体的な評価プロセスやプロンプト設計の改善手法を紹介した。特に、**再現性の高い評価手法の重要性**、**LLM Judgeと人間監視の組み合わせ**、および**顧客説明責任を果たすためのプロンプト設計**に焦点が当てられている。対象はAIエージェント開発者、品質保証担当者、研究者。

---

## 講演の構成（Structure）

- **導入**
  - AIエージェントの「品質担保」には、単なるテストではなく、性能劣化・社会的リスクも含めた包括的な評価が必要。
  - 評価とテストは別概念であり、評価は「性能理解と改善」に関する継続的プロセス。

- **背景**
  - テストは主に「正しく動作しているか」を確認する工程。
  - 評価は「AIがどのように良い／悪い結果を出しているか」を分析し、改善点を明確にするための工程。
  - 定量評価における**アノテーションのばらつき**や**採点基準のドリフト**が課題。

- **技術的内容**
  - **評価プロセスの4段階モデル**
    1. **障壁の解体**：チーム間でAI特性とリスクの認識を共有。
    2. **正常系テスト**：仕様・シナリオの明確化。
    3. **訂正評価・エラー分析**：不具合原因の特定。
    4. **本番運用テスト**：実データを用いた継続的評価。
  - **生成タスク評価の難しさ**
    - 正解基準が曖昧。
    - 実績データが少なくコールドスタート問題が発生。
  - **LLM Judgeの導入**
    - 自動評価とガードレール（品質監視）を組み合わせ、再現性と精度を向上。
  - **評価プロンプトの設計**
    - 良いプロンプトの条件：
      1. 再現性（第三者が同様の結果を得られる）
      2. 詳細性（抜け漏れなく明示的な記述）
      3. 説明責任（顧客に説明できる論理性）

- **事例／実践**
  - 不良な評価例：
    - 「有益さを1〜10点で評価」など曖昧なスコアリングでは再現性が低下。
  - 改善策：
    - 評価軸を明確に（例：根拠の論理性、有用性、忠実性など）。
    - 各観点に定量ルールを付与（例：5点＝「期待を上回る実用的な提案を含む」）。
  - **サブミットコンテント（SubmitContent）ツールの改良**
    - 旧仕様：アクセプト／リジェクトの二値判断のみ。
    - 改善後：各評価観点（安全性・正確性・忠実性・有用性）に基づきスコアリング＋説明文生成。
    - 最終判断をLLMから人間側（ユーザー）へ移行し、評価基準の透明性を向上。

- **議論・質疑応答**
  - LLMの評価における「説明可能性」の欠如が品質低下につながる。
  - 評価指標を定義せずに自動評価を行うと再現性が失われる。

- **まとめ**
  - 品質評価は「AIの能力」と「システムとしての実務遂行力」を分けて評価すべき。
  - 再現性・説明性・責任分担の明確化が品質担保の鍵。
  - LLM Judgeや自動テスト基盤の継続的運用で品質向上が可能。

---

## 発言者別メモ（Speakers）

- **登壇者B（品質評価担当）**
  - **発言要旨**：
    - 評価は単なるバグ検知ではなく「理解と改善」のプロセス。
    - 定量評価よりも、まず障壁解体と正常系確認を重視。
    - 生成タスクの曖昧性に対してLLM Judgeと人間監視を組み合わせる。
  - **重要なキーワード**：
    - 品質担保、再現性、LLM Judge、プロンプト設計、評価指標、有用性スコア。
  - **特徴的な見解**：
    - 「評価基準の曖昧さがばらつきを生む。曖昧さを減らすプロンプト設計が品質向上の第一歩。」

---

## 技術・概念の整理（Key Concepts）

- **障壁解体（Barrier Breakdown）**
  - チーム内でAI特性・リスクを共有する初期段階。
- **正常系テスト（Normal Case Testing）**
  - 使用仕様やシナリオを確認し、曖昧性を排除。
- **LLM Judge**
  - LLMが生成物を自動的に評価する仕組み。ガードレール（品質監視）と併用。
- **再現性（Reproducibility）**
  - 評価を誰が実施しても同様の結果になる特性。
- **有用性スコア（Usefulness Score）**
  - 出力が実用的・革新的である度合いを数値化。
- **プロンプトの説明責任**
  - 顧客や上位システムに対し、なぜその結果になったかを説明可能にする設計指針。

---

## 実務・応用のポイント（Practical Insights）

- **ポイント1：**
  - 定量評価の前に、認識のすり合わせ（障壁解体）と仕様整理を優先。
- **ポイント2：**
  - 曖昧な評価軸（例：「有益さ」）は避け、観点を分解してルール化。
- **ポイント3：**
  - 自動評価は「スコア＋説明」をセットで出力し、再現性を担保。
- **ポイント4：**
  - LLM Judgeの結果をモニタリングし、閾値以下なら改善を自動トリガー。
- **ポイント5：**
  - 最終判断権限を人間側に置くことで、説明責任と透明性を両立。

---

## 今後の課題・議論点（Open Questions）

- LLM Judgeの評価信頼性（どの程度人間評価に一致するか）。
- 自動評価と監視システムを統合した継続的品質保証パイプラインの設計。
- 顧客説明可能な評価レポートの標準化。
- 多観点評価のスコア統合方法（重み付け・正規化など）。

---

## 自分の気づき／補足（Personal Notes）

- プロンプト設計を通じた「再現性の担保」は、RAS/Graph-RAGの評価設計にも応用可能。
- SubmitContentの改良思想は、**評価API設計**や**自動検証ツール（EvalOps）**にも通じる。
- 「評価観点の透明化」と「責任分担の可視化」は、今後のエージェント社会実装に不可欠。
- 参考にすべき資料：
  - Anthropic “Constitutional AI” の評価基準
  - RAGAS Metrics（有用性・忠実性のスコア設計）
  - Prom
