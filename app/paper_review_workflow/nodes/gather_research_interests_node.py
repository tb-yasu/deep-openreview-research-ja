"""Node for gathering research interests interactively."""

import json
import re
from typing import Any

from langchain_openai import ChatOpenAI
from loguru import logger

from app.paper_review_workflow.models.state import PaperReviewAgentState


class GatherResearchInterestsNode:
    """å¯¾è©±çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç ”ç©¶èˆˆå‘³ã‚’åé›†ã™ã‚‹ãƒãƒ¼ãƒ‰."""
    
    def __init__(self, min_keywords: int = 3):
        """GatherResearchInterestsNodeã‚’åˆæœŸåŒ–.
        
        Args:
        ----
            min_keywords: æœ€å°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰
        """
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0, max_tokens=500)
        self.min_keywords = min_keywords
    
    def __call__(self, state: PaperReviewAgentState) -> dict[str, Any]:
        """ç ”ç©¶èˆˆå‘³ã‚’å¯¾è©±çš„ã«åé›†.
        
        Args:
        ----
            state: ç¾åœ¨ã®çŠ¶æ…‹
            
        Returns:
        -------
            æ›´æ–°ã•ã‚ŒãŸçŠ¶æ…‹ã®è¾æ›¸
        """
        criteria = state.evaluation_criteria
        
        # åˆæœŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        if criteria.research_description:
            logger.info("ç ”ç©¶èˆˆå‘³ã®èª¬æ˜ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™...")
            initial_keywords = self._extract_keywords(criteria.research_description)
        else:
            initial_keywords = criteria.research_interests or []
        
        logger.info(f"\næŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ({len(initial_keywords)}å€‹):")
        for i, kw in enumerate(initial_keywords, 1):
            logger.info(f"  {i}. {kw}")
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå°‘ãªã„å ´åˆã€è¿½åŠ è³ªå•
        if len(initial_keywords) < self.min_keywords:
            logger.info(f"\nã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒ{self.min_keywords}å€‹æœªæº€ã®ãŸã‚ã€è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã¾ã™...\n")
            additional_keywords = self._ask_for_more_details(
                criteria.research_description or "",
                initial_keywords
            )
            
            # ãƒãƒ¼ã‚¸ã—ã¦é‡è¤‡å‰Šé™¤
            all_keywords = list(set(initial_keywords + additional_keywords))
            
            logger.info(f"\nè¿½åŠ ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {additional_keywords}")
        else:
            all_keywords = initial_keywords
        
        # æœ€çµ‚ç¢ºèª
        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ“‹ æœ€çµ‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ ({len(all_keywords)}å€‹):")
        for i, kw in enumerate(all_keywords, 1):
            logger.info(f"  {i}. {kw}")
        logger.info(f"{'='*80}\n")
        
        # æ›´æ–°ã•ã‚ŒãŸåŸºæº–ã‚’è¿”ã™
        updated_criteria = criteria.model_copy(deep=True)
        updated_criteria.research_interests = all_keywords
        
        return {
            "evaluation_criteria": updated_criteria,
        }
    
    def _extract_keywords(self, description: str) -> list[str]:
        """è‡ªç„¶è¨€èªã®èª¬æ˜ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º.
        
        Args:
        ----
            description: ç ”ç©¶èˆˆå‘³ã®è‡ªç„¶è¨€èªèª¬æ˜
            
        Returns:
        -------
            æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        try:
            prompt = f"""Extract key research topics from the following description.
Return 5-8 important keywords or phrases that represent the main research interests.

Description:
{description}

Return ONLY a JSON array of keywords, like:
["keyword1", "keyword2", "keyword3", ...]

Rules:
- Use lowercase
- Be specific and technical
- Include 5-8 keywords
- Focus on the most important topics
"""
            
            response = self.llm.invoke(prompt)
            response_text = response.content.strip()
            
            # JSONãƒ‘ãƒ¼ã‚¹
            keywords = self._parse_json_response(response_text)
            
            return keywords
            
        except Exception as e:
            logger.warning(f"Failed to extract keywords: {e}. Using empty list.")
            return []
    
    def _ask_for_more_details(
        self,
        initial_description: str,
        current_keywords: list[str]
    ) -> list[str]:
        """è¿½åŠ è³ªå•ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¼•ãå‡ºã™ï¼ˆã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ä»˜ãï¼‰.
        
        Args:
        ----
            initial_description: åˆæœŸã®èª¬æ˜
            current_keywords: ç¾åœ¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
            
        Returns:
        -------
            è¿½åŠ ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        try:
            # LLMã«è³ªå•ã¨ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã•ã›ã‚‹
            question_prompt = f"""Based on this research description and current keywords, 
generate 2-3 specific follow-up questions in Japanese with keyword suggestions.

Initial description: {initial_description}
Current keywords: {current_keywords}

For each question, provide:
- The question in Japanese
- 3-5 example keywords (in English, lowercase) that would be relevant answers

Generate questions about:
- Specific methods or techniques they're interested in
- Application domains or use cases
- Related subfields or emerging topics

Return ONLY a JSON array of objects:
[
  {{
    "question": "è³ªå•1?",
    "suggestions": ["keyword1", "keyword2", "keyword3"]
  }},
  {{
    "question": "è³ªå•2?",
    "suggestions": ["keyword4", "keyword5"]
  }}
]
"""
            
            response = self.llm.invoke(question_prompt)
            questions_data = self._parse_json_response(response.content)
            
            # è³ªå•ã‚’è¡¨ç¤ºã—ã¦å›ç­”ã‚’åé›†
            logger.info("\nè¿½åŠ ã®è³ªå•ã«ãŠç­”ãˆãã ã•ã„:\n")
            answers = []
            
            for i, item in enumerate(questions_data, 1):
                if isinstance(item, dict):
                    question = item.get("question", "")
                    suggestions = item.get("suggestions", [])
                else:
                    # äº’æ›æ€§ã®ãŸã‚ã€æ–‡å­—åˆ—ã®å ´åˆã‚‚å¯¾å¿œ
                    question = str(item)
                    suggestions = []
                
                logger.info(f"{i}. {question}")
                
                # ã‚µã‚¸ã‚§ã‚¹ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤º
                if suggestions:
                    suggestion_text = ", ".join(suggestions[:5])
                    logger.info(f"   [ä¾‹: {suggestion_text}]")
                
                try:
                    answer = input("   å›ç­”: ")
                    if answer.strip():
                        answers.append(answer)
                    else:
                        logger.info("   ï¼ˆã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼‰")
                except (EOFError, KeyboardInterrupt):
                    logger.info("\nï¼ˆã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼‰")
                    break
            
            # å›ç­”ã‹ã‚‰è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            if answers:
                combined_answers = " ".join(answers)
                additional_prompt = f"""Extract additional research keywords from these answers:

{combined_answers}

Return 3-5 additional keywords as JSON array.
Avoid duplicating: {current_keywords}
Use lowercase and be specific.
"""
                
                response = self.llm.invoke(additional_prompt)
                additional_keywords = self._parse_json_response(response.content)
                
                return additional_keywords
            
            return []
            
        except Exception as e:
            logger.warning(f"Failed to ask for more details: {e}")
            return []
    
    def _parse_json_response(self, response_text: str) -> list:
        """LLMã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONé…åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹.
        
        Args:
        ----
            response_text: LLMã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
        -------
            ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸãƒªã‚¹ãƒˆï¼ˆæ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ or ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆï¼‰
        """
        try:
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                json_str = response_text.split("```")[1].split("```")[0].strip()
            else:
                json_str = response_text.strip()
            
            # JSONã‚’ãƒ‘ãƒ¼ã‚¹
            result = json.loads(json_str)
            
            if isinstance(result, list):
                # ãƒªã‚¹ãƒˆã®è¦ç´ ãŒè¾æ›¸ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                if result and isinstance(result[0], dict):
                    return result
                # æ–‡å­—åˆ—ã®å ´åˆã¯å°æ–‡å­—åŒ–ã—ã¦è¿”ã™
                return [str(item).lower().strip() for item in result]
            
            return []
            
        except Exception as e:
            logger.warning(f"Failed to parse JSON response: {e}")
            logger.debug(f"Response: {response_text[:200]}...")
            return []

